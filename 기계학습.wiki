 * 관련 항목 : [컴퓨터 관련 정보], [인공지능]

[[목차]]

= 개요 =
영어 : Machine Learning

[[인공지능]]의 대표적인 방법이었던 전문가 시스템은 사람이 직접 많은 수의 규칙을 집어넣는 것을 전제로 하였다. 이같은 접근 방법은 과학에 기반한 학문들, 예를들어 [[의학]]이나 [[생물]] 분야에서는 큰 역할을 할 수 있었다. 의사들의 진단을 도와주는 전문가 시스템에 기반한 [[프로그램]]을 생각해보면 인간이 지금까지 발견한 의학적인 규칙들을 [[데이터베이스]]화 하여 등록시켜주면 되는 것이었다.

하지만, 시간이 지남에 따라 세상은 사람조차 스스로 어떻게 하는지 모르는 영역을 요구하기 시작했다. 대표적으로 음성인식을 들 수 있겠다. [[애플]]의 [[시리]] 같은 프로그램을 만든다고 생각해보자. 일단 [[사람]]이 어떤 문장을 말했는지 소리 -> 알파벳으로 알아들을 수 있어야 하며, [[알파벳]]으로 이루어진 그 문장이 어떠한 의미를 갖는지 해석할 수 있어야 한다. 이 같은 시스템은 사람이 하나하나 규칙을 만들어 준다고 형성될 수 있지 않다. 소리 같은 경우에는 [[컴퓨터]]에 [[PCM]]의 형태로 전달이 되는데 대체로 이는 1초에 최소 [[리그베다 위키]] 항목 하나 분량의 [[데이터]]를 포함하고 있다. 절대로 "열이 많이 나고 오한이 있고 구토증상이 있으므로 독감이다"라는 쉬운 조건부로 해결될 문제가 아닌 것이다.

그리하여 나온 방법이 기계학습이다. 이름에서 알 수 있듯이 기계학습은 기계, 즉 컴퓨터를 인간처럼 학습시켜 '''스스로 규칙을 형성'''할 수 있지 않을까 하는 시도에서 비롯되었다. 주로 통계적인 접근 방법을 사용하는데, 위의 독감의 예와 반대로 "독감이 걸린 사람은 대부분 열이 많이 나고 오한이 있고 구토 증상이 있었다"라는 통계에 기반하여 독감을 진단하는 것이다. 예시를 보면 알 수 있듯이 이는 인간이 하는 추론 방식과 유사하고 매우 강력하다.

기계학습의 발전으로 인해 현재의 거의 모든 시스템(인공지능, 검색엔진, 광고, 마케팅, 주식, 로봇, 인사활동, 등등)은 기계학습의 방법론 없이는 정상적으로 가동되지 않게 되었다. 

= 선수과목 =

기계학습을 공부하고자 하면 기본적으로 컴퓨터학과에서 다루는 대부분의 수학 과목을 필요로 한다. 대표적으로

 * 이산수학
 * 미적분
 * 확률과 통계
 * 선형대수

등이 있다. 그렇다고 이 수학과목들을 전부 전문가 수준으로 익힐 필요는 없고 기계학습의 방법론을 이해하고 그곳에 적용할 수 있는 스킬을 기르는 것이 무엇보다 중요하다.

= 정의 =

기계학습의 명확한 정의는 없고 대체로 다음 중 하나를 따르는 것으로 보인다.

 * 주어진 어떠한 데이터, 상황, 혹은 그 시퀀스(sequence) x에서의 레이블(label) 혹은 확률 y로의 매핑 함수 y = f(x)를 구하는 것
 예를들어 사진속에 있는 동물을 인식하는 함수가 있을 때, "강아지 사진"이 주어지면 사진 자체는 입력 x, 강아지는 레이블 y가 되는 것이다.
 * 주어진 입력 시퀀스 x_1, x_2, ... x_n이 있을 때, 그 다음 입력 x_n+1을 예측하는 것
 이 정의에 맞는 대표적인 분야는 '''주식 예측'''이 있다.

== 기능 ==

기계학습으로 할 수 있는 기능엔 크게 두 가지가 있다.

 * 분류 (Classification) : 주어진 입력 x의 레이블 y를 추정해내는 것
 y는 1/0의 이진값이거나 혹은 확률이나 실수값으로 주어질 수 있다. 미소녀 이미지를 주었을 때 안경을 끼고 있는지 아닌지(이진값) 분류하거나 혹은 얼마나 로리한지(확률값) 분류할 때 사용된다.
 * 군집화 (Clustering) : 주어진 입력 x와 비슷한 입력들의 군집(cluster)을 추정해내는 것
 미소녀 이미지를 1만장 정도 주고 [[머리색]]을 기준으로 군집화 하라고 할 경우가 속할 수 있다. 이 때 머리색의 기준을 특정한 RGB 값으로 줄 수도 있지만, 알고리즘에 따라 자체적으로 학습을 통해 기준을 설정할 수 있게 할 수도 있다.

== 학습방법 ==

기계학습의 학습 방법엔 크게 3가지가 있다.

 * 교사 학습(Supervised Learning) : 사람이 [[교사]]로써 각각의 입력에 대해 레이블을 달아서 컴퓨터한테 주면 컴퓨터가 그것을 학습하는 것이다. 사람이 직접 개입하므로 정확도가 높은 데이터를 사용할 수 있다는 장점이 있다. 대신에 사람이 직접 레이블을 달아야 하므로 인건비 문제가 있고, 데이터도 적다는 문제가 있다. 주로 분류기를 만드는데 사용된다
 * 비교사 학습(Unsupervised Learning) : 사람 없이 컴퓨터가 스스로 레이블 되어 있지 않은 데이터에 대해 학습하는 것. 정답이 없는 문제를 푸는 것이므로 학습이 맞게 됐는지 확인할 길은 없지만, 인터넷에 있는 거의 모든 데이터가 레이블이 없는 형태로 있으므로 앞으로 기계학습이 나아갈 방향으로 설정되어 있기도 하다. 주로 군집화를 하는데 사용된다.
 * 강화 학습(Reinforcement Learning) : 현재의 상황을 보고 어떤 행동을 하면 어떤 보상을 받을지 예측하여 좋은(positive) 보상을 받는 쪽으로 행동하는 학습 방법. 위 방법들과는 다르게 실시간으로 학습을 진행하며 목표에 도달하기 위한 최적의 절차(procedure)을 찾는 것을 목표로 한다. 주로 로봇 제어에서 사용된다.

= 알고리즘 =

기계학습의 개략적인 [[알고리즘]]에 대해 기술한다. 이것에 대해 자세히 [[공부]]하고 싶으면 [[컴퓨터학과]]에 진학하는 것을 추천한다.

== 확률 기반 ==

확률 기반 기계학습 알고리즘은 대부분 베이즈 정리에 기반한다. 베이즈 정리는 다음과 같은 형태로 확률적 추론에 이용되는 정리이다.

${P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)}}$

여기서 P(Y|X)는 조건부 확률로 "X가 주어졌을 때 Y가 발생할 확률"로 생각하면 된다.

예를 들어 수식을 설명하자면 X가 "열이 많이 난다"고 Y가 "독감"이라면, P(Y|X)는 열이 많이 나는 환자가 독감 환자일 확률 확률, P(X|Y)는 독감 환자가 열이 많이나는 확률, P(X)는 환자 중에 열이 많이나는 환자가 있을 확률, P(Y)는 환자 중에 독감이 발생한 환자가 있을 확률이다.

여기서 베이즈 정리의 강력함은 "열이 많이나는 환자가 독감 환자일 확률"(구하기 힘든 값)을 "독감 환자가 열이 많이 날 확률"(구하기 쉬운 값)로 추정할 수 있다는데 있다.

아래는 베이즈 정리에 기반한 대표적인 알고리즘들이다.

=== Naive Bayes Classifier (NBC) ===

이름에서 알 수 있듯이 베이즈 정리를 활용한 가장 단순한(naive) 분류기이다.

$Y$ 가 일어날 원인 ${X_1, X_2, X_3, ..., X_N}$ 이 '''서로 독림임을 가정'''하면 ${P(X|Y) = \Pi_{i=1}^N P(X_i|Y)}$ 임을 이용하여 ${P(Y|X) = \frac{P(X|Y)P(Y)}{P(X)} \simeq \frac{\Pi_{i=1}^N P(X_i|Y)P(Y)}{P(X)}}$ 으로 레이블을 추정하는 알고리즘이다.

여기서 각 확률값의 연산과 증명은 대학교 미적분 때 배우는 lagrange multiplier를 통해 진행할 수 있다.
=== Hidden Markov Model (HMM) ===

== 기하 기반 ==

주어진 입력의 특징(feature)을 벡터(vector)로 만들어 특징 벡터끼리의 [[기하학]]적인 관계를 기반으로 추론을 진행하는 시스템을 이야기한다. 주로 벡터끼리의 거리나 코사인 유사도를 사용한다.

예를들어 가장 원시적인 형태의 검색엔진의 경우에는 문서에 어떤 단어가 몇 개 있는지를 벡터로 만든 후, 검색어도 마찬가지로 벡터로 만들어 벡터 유사도를 통해 문서를 순위화 하는 Vector Space Model을 사용하였다.

=== K-Means ===

주어진 입력을 군집화 하는 비교사 학습 방법이다. 총 K 개의 클러스터가 있다고 가정하고, 특징 공간(feature space)에서 K 개의 중간점(centroid)를 찾는 알고리즘이다.

=== K Nearest Neighbors (KNN) ===

레이블 되어 있는 학습 데이터가 있을 때, 각 레이블마다 학습 데이터의 중간점을 구한다. 그 후 입력된 특징 벡터 X에 가장 가까운 중간점에 해당하는 레이블을 사용하는 분류기이다.

=== Support Vector Machine (SVM) ===

Support vector란 특징 공간에서 주어진 두 분류의 데이터를 구분지을 수 있는 최적(optimal)의 초평면(hyperplane)을 의미한다. SVM은 그러한 support vector를 찾는 알고리즘으로 두 분류에서 가장 가까운 데이터를 하나씩 찾아서 그 거리를 계산했을 때 가장 멀어질 수 있는 초평면을 찾는 것을 목표로 한다.

이것만 하면 단순한 linear classifier이어서 xor과 같이 직선으로 나눌 수 없는 함수는 학습을 진행하지 못하지만, SVM은 여기에 kernel function이란 개념을 도입하여 특징 공간을 접어버리거나 꼬아버려 선형으로 분류할 수 있게 만들어버린다.

기하 기반의 기계학습의 끝판왕으로 이것으로 필기인식, 사진 안에 있는 물체 인식, 영화 리뷰 분석 등 온갖 문제를 해결한다.
== 인공신경망 ==

가상의 [[뉴런]]을 수학적으로 모델링한 후 시뮬레이션하여 인간의 뇌와 같은 학습 능력을 갖게하고자 하는 알고리즘이다. 주로 패턴인식에 많이 쓰이는데, 다른 알고리즘들에 향상된 성능을 가진데 반해 학습하는데 시간이 오래걸리고 연산량이 많으며 학습 데이터를 아주 많이 필요로 하는 단점을 갖고 있다.

뉴런 항목을 보면 알 수 있듯이 뉴런은 수상돌기에서 주변에 있는 다른 뉴런들로부터 오는 신호를 수용한 뒤, 신호의 강도가 특정 역치값을 넘어가면 축삭돌기를 통해 다른 뉴런에 신호를 보내는 세포이다. 이를 수학적으로 모델링 하면 다른 뉴런에서 들어오는 신호 벡터 $x$ 에 신호를 수용하는 수용체의 민감도(가중치) 벡터 $w$ 를 곱한 후, 역치값 $b$ 과 비교하는 형태의 모델이 나오게 된다.

따라서 인공 뉴런의 출력은 $wx + b$ 의 값이 되게 되는데 이 식을 그대로 사용할 경우 출력값이 $x$ 에 따라 실수 전체 범위에서 선형적인 값을 갖는 linear model이라 하고, 분석능력이 상당히 떨어지는 원시적인 모델이 되어버린다. 이를 해결하기 위해 non-linear model이 나왔는데 실제 뉴런의 행동 방식처럼 역치부분에서 값이 극적으로 변하는 함수를 사용한다. 대표적으로 sigmoid 함수를 사용하는 logistic model이 있고, tanh나 softmax 함수를 사용하는 다른 여러 모델들이 있으며 이 때 사용되는 함수를 활성화함수(activation function)라 한다.
=== Perceptron ===

Perceptron은 위에서 설명한 뉴런의 수학적 모델을 일컫는 용어이다. 이 알고리즘은 이름 그대로 하나의 뉴런을 사용하며 학습 데이터를 가장 잘 설명할 수 있는 최적의 패러미터( $w, b$ )값을 찾는다.

학습은 학습 데이터를 넣은 후 결과가 원하던 결과보다 크면 결과가 작아지게 패러미터를 조정하고 원하던 결과보다 작으면 커지게 패러미터를 조정하는것을 반복한다. 이것으로 학습이 가능하다는 것은 perceptron convergence theorem이란 이름으로 증명이 되어 있다.
=== Multilayer Perceptron (MLP) ===

=== Deep Learning ===
== 기타 ==

= 예시 =

구글에서 인공신경망을 사용하여 이미지를 보고 이미지를 설명하는 캡션을 작성하는 인공지능을 만들었다고 한다. [http://www.etnews.com/20141120000002]

= 관련항목 =
